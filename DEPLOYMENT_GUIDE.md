# üöÄ Deployment Guide - Production Deployment Options

## Overview

This guide provides the most **performant and efficient** ways to deploy the feature-complete Discharge Summary Generator application.

---

## üéØ Recommended Deployment Strategy

### **Option 1: Vercel + Railway (Recommended - Easiest & Fastest)**

**Best for**: Quick deployment, automatic scaling, minimal configuration

#### Frontend (React + Vite) ‚Üí Vercel
- **Deployment Time**: 2-5 minutes
- **Performance**: Global CDN, edge functions
- **Cost**: Free tier available
- **SSL**: Automatic HTTPS

**Steps:**
```bash
# 1. Install Vercel CLI
npm install -g vercel

# 2. Login to Vercel
vercel login

# 3. Deploy (from project root)
vercel --prod

# Configuration is automatic via vite.config.js
```

**Vercel Configuration** (`vercel.json` - create this):
```json
{
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "framework": "vite",
  "devCommand": "npm run dev",
  "installCommand": "npm install",
  "env": {
    "VITE_ANTHROPIC_API_KEY": "@anthropic_api_key",
    "VITE_OPENAI_API_KEY": "@openai_api_key",
    "VITE_GOOGLE_API_KEY": "@google_api_key"
  }
}
```

#### Backend (Node.js Proxy) ‚Üí Railway
- **Deployment Time**: 3-5 minutes
- **Performance**: Auto-scaling, low latency
- **Cost**: Free tier available
- **Database**: Easy to add if needed

**Steps:**
```bash
# 1. Install Railway CLI
npm install -g @railway/cli

# 2. Login to Railway
railway login

# 3. Deploy backend (from backend directory)
cd backend
railway init
railway up

# 4. Set environment variables
railway variables set ANTHROPIC_API_KEY=your_key
railway variables set OPENAI_API_KEY=your_key
railway variables set GEMINI_API_KEY=your_key
railway variables set PORT=3001
```

**Advantages:**
- ‚úÖ Zero DevOps knowledge required
- ‚úÖ Automatic CI/CD (git push deploys)
- ‚úÖ Free tier generous enough for testing/MVP
- ‚úÖ Scales automatically
- ‚úÖ Built-in monitoring

**Performance:**
- Frontend: ~100ms global response time (CDN)
- Backend: ~50-200ms API response
- Total: **15-35s for summary generation** (mostly LLM processing)

---

### **Option 2: AWS (Production Grade - Best Performance)**

**Best for**: Enterprise deployment, maximum control, HIPAA compliance

#### Architecture:
```
CloudFront (CDN)
    ‚Üì
S3 (Static Assets)
    
API Gateway
    ‚Üì
Lambda (Backend Proxy)
    ‚Üì
DynamoDB (Optional: Cache)
```

**Frontend Deployment:**
```bash
# 1. Build production bundle
npm run build

# 2. Create S3 bucket
aws s3 mb s3://dcs-frontend-prod

# 3. Upload build
aws s3 sync dist/ s3://dcs-frontend-prod --acl public-read

# 4. Create CloudFront distribution
aws cloudfront create-distribution \
  --origin-domain-name dcs-frontend-prod.s3.amazonaws.com \
  --default-root-object index.html
```

**Backend Deployment (Lambda):**
```bash
# 1. Install Serverless Framework
npm install -g serverless

# 2. Create serverless.yml (backend/)
# 3. Deploy
cd backend
serverless deploy --stage prod
```

**serverless.yml Example:**
```yaml
service: dcs-backend
provider:
  name: aws
  runtime: nodejs18.x
  region: us-east-1
  environment:
    ANTHROPIC_API_KEY: ${env:ANTHROPIC_API_KEY}
    OPENAI_API_KEY: ${env:OPENAI_API_KEY}
    
functions:
  proxy:
    handler: server.handler
    events:
      - http:
          path: api/{proxy+}
          method: ANY
          cors: true
```

**Advantages:**
- ‚úÖ Best performance (global CDN)
- ‚úÖ HIPAA compliant (with BAA)
- ‚úÖ Infinite scalability
- ‚úÖ Advanced monitoring (CloudWatch)
- ‚úÖ Fine-grained cost control

**Performance:**
- Frontend: ~50ms global response (CloudFront)
- Backend: ~30-150ms API response (Lambda)
- **Optimized for high traffic**

**Cost Estimate:**
- Small practice (<100 users): ~$20-50/month
- Medium practice (100-500 users): ~$100-200/month
- Enterprise: Pay per use, highly scalable

---

### **Option 3: Docker + DigitalOcean (Balanced)**

**Best for**: Self-hosted, predictable costs, moderate traffic

#### Single Docker Compose Setup:
```yaml
version: '3.8'
services:
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - backend
      
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    restart: unless-stopped
```

**Dockerfile.frontend:**
```dockerfile
# Build stage
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# Production stage
FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

**Deploy to DigitalOcean:**
```bash
# 1. Create droplet (App Platform or Droplet)
# Via App Platform (easiest):
doctl apps create --spec app.yaml

# Or via Droplet (more control):
doctl compute droplet create dcs-prod \
  --size s-2vcpu-4gb \
  --image docker-20-04 \
  --region nyc1

# 2. SSH and deploy
ssh root@your-droplet-ip
git clone your-repo
cd your-repo
docker-compose up -d
```

**Advantages:**
- ‚úÖ Predictable monthly cost ($20-50)
- ‚úÖ Full control over infrastructure
- ‚úÖ Easy to backup/restore
- ‚úÖ Good performance for medium traffic

---

## ‚ö° Performance Optimization Recommendations

### 1. **Enable Build Optimizations**

Already configured in `vite.config.js`, but ensure:
```javascript
build: {
  outDir: 'dist',
  sourcemap: false,  // Disable in production
  minify: 'terser',
  rollupOptions: {
    output: {
      manualChunks: {
        'react-vendor': ['react', 'react-dom'],
        'llm-vendor': ['@anthropic-ai/sdk', 'openai', '@google/generative-ai'],
        'ui-vendor': ['lucide-react', 'recharts']
      }
    }
  }
}
```

### 2. **Implement Caching**

Add to backend proxy (`server.js`):
```javascript
// Cache successful LLM responses (optional)
const cache = new Map();

app.post('/api/anthropic', async (req, res) => {
  const cacheKey = JSON.stringify(req.body);
  
  if (cache.has(cacheKey)) {
    console.log('Cache hit');
    return res.json(cache.get(cacheKey));
  }
  
  // ... make API call ...
  cache.set(cacheKey, result);
});
```

### 3. **Use Environment Variables Properly**

**Frontend** (`.env.production`):
```bash
VITE_API_PROXY_URL=https://your-backend.railway.app
VITE_ENABLE_ANALYTICS=true
```

**Backend** (`.env`):
```bash
NODE_ENV=production
PORT=3001
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=...
CORS_ORIGIN=https://your-frontend.vercel.app
```

### 4. **Enable Compression**

Add to backend:
```javascript
import compression from 'compression';
app.use(compression());
```

### 5. **Monitor Performance**

Add basic monitoring:
```javascript
// server.js
app.use((req, res, next) => {
  const start = Date.now();
  res.on('finish', () => {
    const duration = Date.now() - start;
    console.log(`${req.method} ${req.path} - ${duration}ms`);
  });
  next();
});
```

---

## üîí Security Checklist

Before deploying to production:

- [ ] **API Keys**: Never commit API keys (use environment variables)
- [ ] **CORS**: Configure proper CORS origins (no wildcards)
- [ ] **Rate Limiting**: Add rate limiting to backend
- [ ] **HTTPS**: Ensure SSL certificates (automatic on Vercel/Railway)
- [ ] **Input Validation**: Validate all inputs on backend
- [ ] **Error Handling**: Don't expose stack traces in production
- [ ] **HIPAA Compliance**: Use BAA-compliant services if handling PHI

---

## üìä Deployment Comparison

| Factor | Vercel+Railway | AWS | Docker+DO |
|--------|----------------|-----|-----------|
| **Setup Time** | 5-10 min ‚≠ê | 30-60 min | 15-30 min |
| **Cost (MVP)** | $0-20/mo ‚≠ê | $20-50/mo | $20-50/mo |
| **Scalability** | Auto ‚≠ê | Unlimited ‚≠ê | Manual |
| **Performance** | Excellent | Best ‚≠ê | Good |
| **Control** | Limited | Full ‚≠ê | High |
| **Maintenance** | Minimal ‚≠ê | Medium | Medium |
| **HIPAA Ready** | Yes* | Yes ‚≠ê | Yes* |
| **Best For** | MVP, Startups | Enterprise | Self-hosted |

*With proper configuration

---

## üéØ Final Recommendation

### **For Immediate Deployment (Today):**
üëâ **Use Vercel + Railway** (Option 1)

**Why:**
1. **Fastest**: Deploy in <10 minutes
2. **Free**: Start with free tiers
3. **Automatic**: Git push = deploy
4. **Reliable**: 99.9% uptime
5. **Scalable**: Grows with you

### **For Enterprise/HIPAA:**
üëâ **Use AWS** (Option 2)

**Why:**
1. **Compliant**: HIPAA BAA available
2. **Performance**: Best in class
3. **Scalable**: Handles any load
4. **Professional**: Trusted by healthcare

---

## üöÄ Quick Start (5 Minutes)

```bash
# 1. Frontend
npm install -g vercel
vercel login
vercel --prod

# 2. Backend
npm install -g @railway/cli
railway login
cd backend
railway init
railway up

# 3. Set environment variables in Railway dashboard
# 4. Update frontend VITE_API_PROXY_URL to Railway URL
# 5. Redeploy frontend: vercel --prod

# Done! Your app is live. üéâ
```

---

## üìû Support

For deployment issues:
- Vercel: https://vercel.com/docs
- Railway: https://docs.railway.app
- AWS: https://aws.amazon.com/getting-started/

---

**Last Updated**: 2024-10-14  
**Application Version**: 1.0 Production Ready  
**Recommended**: Vercel + Railway for fastest deployment
